#!/usr/bin/env python3
"""
CIFAR-10 â†’ 128-dim unit-sphere latent code
å¯é‡å»ºã€å¯ä¿å­˜ csvã€å¯ç»§ç»­è®­ç»ƒï¼ˆæ”¹resumeï¼‰
"""
import os, time
import numpy as np
import pandas as pd
import torch, torch.nn as nn, torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.cuda.amp import autocast, GradScaler
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
from torch.utils.tensorboard import SummaryWriter
from torchvision.utils import save_image
from torchvision import datasets, transforms
from pathlib import Path
from lpips import LPIPS

# ---------- å…¨å±€ ----------
torch.manual_seed(2024)
np.random.seed(2024)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"Using device: {device}")

# ---------- è·¯å¾„ ----------
ROOT = Path("/root/autodl-tmp/mapper-CIFAR10")
DATA_DIR = ROOT / "datasets"
CKPT_DIR = ROOT / "ckpt"
os.makedirs(CKPT_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)

# ---------- è¶…å‚ ----------
BATCH = 256
EPOCHS = 400
LATENT = 128
LR = 2e-4
SAVE_EVERY = 10
LPIPS_W = 0.2
CLS_W = 0.1

# ---------- è¯»å– CIFAR-10 (ä½¿ç”¨ torchvision) ----------
transform = transforms.ToTensor()  # å°†æ•°æ®è½¬ä¸º [0,1] çš„ Tensor
train_ds = datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=transform)
test_ds = datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=transform)

train_loader = DataLoader(train_ds, BATCH, shuffle=True,
                          num_workers=8, pin_memory=True, drop_last=True)
test_loader = DataLoader(test_ds, BATCH, shuffle=False,
                         num_workers=4, pin_memory=True)


# ---------- ç½‘ç»œ (æ‚¨çš„ç½‘ç»œç»“æ„æ²¡æœ‰ç»´åº¦é—®é¢˜ï¼Œæ— éœ€ä¿®æ”¹) ----------
class ResidualBlock(nn.Module):
    def __init__(self, c_in, c_out):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(c_in, c_out, 3, 1, 1, bias=False),
            nn.BatchNorm2d(c_out), nn.ReLU(inplace=True),
            nn.Conv2d(c_out, c_out, 3, 1, 1, bias=False),
            nn.BatchNorm2d(c_out)
        )
        self.skip = nn.Conv2d(c_in, c_out, 1, bias=False) if c_in != c_out else nn.Identity()

    def forward(self, x):
        return F.relu(self.skip(x) + self.net(x))


class Encoder(nn.Module):
    def __init__(self, latent=LATENT):
        super().__init__()
        self.net = nn.Sequential(
            ResidualBlock(3, 64), nn.AvgPool2d(2),  # 16
            ResidualBlock(64, 128), nn.AvgPool2d(2),  # 8
            ResidualBlock(128, 256), nn.AvgPool2d(2),  # 4
            ResidualBlock(256, 512), nn.AvgPool2d(2),  # 2
            nn.Flatten(),
            nn.Linear(512 * 2 * 2, 512), nn.ReLU(inplace=True),
            nn.Linear(512, latent)
        )

    def forward(self, x):
        return F.normalize(self.net(x), dim=1)


class Decoder(nn.Module):
    def __init__(self, latent=LATENT):
        super().__init__()
        self.fc = nn.Sequential(
            nn.Linear(latent, 512),
            nn.ReLU(inplace=True),
            nn.Linear(512, 512 * 2 * 2),
            nn.ReLU(inplace=True)
        )
        self.deconv = nn.Sequential(
            nn.ConvTranspose2d(512, 256, 4, 2, 1),  # 2â†’4
            nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1),  # 4â†’8
            nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # 8â†’16
            nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),  # 16â†’32
            nn.BatchNorm2d(32), nn.ReLU(inplace=True),
            nn.Conv2d(32, 3, 1),
            nn.Sigmoid()
        )

    def forward(self, z):
        h = self.fc(z).view(-1, 512, 2, 2)
        return self.deconv(h)


# ---------- æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ ----------
encoder = Encoder().to(device)
decoder = Decoder().to(device)
classifier = nn.Linear(LATENT, 10).to(device)

mse_fn = nn.MSELoss()
lpips_fn = LPIPS(net='vgg').to(device)


def loss_fn(rec, tgt):
    # LPIPS æœŸæœ›è¾“å…¥åœ¨ [-1, 1]
    rec_lpips = rec * 2 - 1
    tgt_lpips = tgt * 2 - 1
    return mse_fn(rec, tgt) + LPIPS_W * lpips_fn(rec_lpips, tgt_lpips).mean()


# ã€ä¿®æ­£ã€‘å°†æ‰€æœ‰å‚æ•°åˆå¹¶åˆ°ä¸€ä¸ªä¼˜åŒ–å™¨
params_to_optimize = list(encoder.parameters()) + list(decoder.parameters()) + list(classifier.parameters())
opt = torch.optim.AdamW(params_to_optimize, lr=LR, weight_decay=1e-4)
sched = CosineAnnealingWarmRestarts(opt, T_0=10, T_mult=2)  # T_0 è®¾ä¸º10ä¸ª epochsï¼Œæ¯ 2*T_0 åå‘¨æœŸåŠ å€
scaler = GradScaler()
writer = SummaryWriter(CKPT_DIR / 'logs')

# ---------- è®­ç»ƒ ----------
best_loss = 1e9
start_time = time.time()
for epoch in range(1, EPOCHS + 1):
    encoder.train();
    decoder.train();
    classifier.train()
    run_recon_loss, run_acc = 0., 0.

    for img, lbl in train_loader:
        img, lbl = img.to(device, non_blocking=True), lbl.to(device, non_blocking=True)
        opt.zero_grad()

        with autocast():
            z = encoder(img)
            rec = decoder(z)
            logits = classifier(z)

            recon_loss = loss_fn(rec, img)
            cls_loss = F.cross_entropy(logits, lbl)
            loss = recon_loss + CLS_W * cls_loss

        scaler.scale(loss).backward()
        scaler.step(opt)
        scaler.update()

        # ã€ä¿®æ­£ã€‘ä½¿ç”¨ä¿å­˜çš„å˜é‡è®¡ç®—æŒ‡æ ‡ï¼Œæé«˜æ•ˆç‡
        run_recon_loss += recon_loss.item()
        run_acc += (logits.detach().argmax(1) == lbl).float().mean().item()

    avg_recon_loss = run_recon_loss / len(train_loader)
    avg_acc = run_acc / len(train_loader)
    print(
        f"[{epoch:03d}/{EPOCHS}] Train ReconLoss={avg_recon_loss:.5f}  Acc={avg_acc:.4f}  LR={sched.get_last_lr()[0]:.2e}")
    writer.add_scalar('Loss/Train_Recon', avg_recon_loss, epoch)
    writer.add_scalar('Acc/Train', avg_acc, epoch)

    # ---------- éªŒè¯ ----------
    encoder.eval();
    decoder.eval();
    classifier.eval()
    test_recon_loss, test_acc = 0., 0.
    with torch.no_grad():
        for img, lbl in test_loader:
            img, lbl = img.to(device), lbl.to(device)
            z = encoder(img)
            rec = decoder(z)
            logits = classifier(z)

            test_recon_loss += loss_fn(rec, img).item()
            test_acc += (logits.argmax(1) == lbl).float().mean().item()

    avg_test_recon_loss = test_recon_loss / len(test_loader)
    avg_test_acc = test_acc / len(test_loader)
    print(f"    â†³ [Test]  ReconLoss={avg_test_recon_loss:.5f}  Acc={avg_test_acc:.4f}")
    writer.add_scalar('Loss/Val_Recon', avg_test_recon_loss, epoch)
    writer.add_scalar('Acc/Val', avg_test_acc, epoch)

    # ã€ä¿®æ­£ã€‘å­¦ä¹ ç‡è°ƒåº¦å™¨åœ¨æ¯ä¸ª epoch åæ›´æ–°
    sched.step()

    # ---------- ä¿å­˜å›¾åƒ & æ¨¡å‹ ----------
    states = {
        'enc': encoder.state_dict(),
        'dec': decoder.state_dict(),
        'cls': classifier.state_dict(),
        'opt': opt.state_dict()
    }
    if epoch % SAVE_EVERY == 0 or epoch == EPOCHS:
        with torch.no_grad():
            sample, _ = next(iter(test_loader))  # ä»æµ‹è¯•é›†å–æ ·æ›´å…·ä»£è¡¨æ€§
            sample = sample[:32].to(device)
            rec = decoder(encoder(sample))
            grid = torch.cat([sample, rec], 0)
            save_image(grid, CKPT_DIR / f'recon_{epoch:03d}.png', nrow=8)

        torch.save(states, CKPT_DIR / f'ae_{epoch:03d}.pth')

    # ã€ä¿®æ­£ã€‘åŸºäºéªŒè¯é›†æŸå¤±ä¿å­˜æœ€ä½³æ¨¡å‹
    if avg_test_recon_loss < best_loss:
        best_loss = avg_test_recon_loss
        print(f"ğŸ‰ New best model saved with Val ReconLoss: {best_loss:.5f}")
        torch.save(states, CKPT_DIR / 'ae_best.pth')

# ---------- æœ€ç»ˆæ¨¡å‹ ----------
torch.save(states, CKPT_DIR / 'ae_final.pth')


# ---------- å¯¼å‡º 128 ç»´æ½œç  csv ----------
@torch.no_grad()
def export_latents(model_path, dataset, split_name):
    print(f"\nExporting latents for {split_name} split...")
    states = torch.load(model_path, map_location=device)
    encoder.load_state_dict(states['enc'])
    encoder.eval()

    # ä½¿ç”¨æ›´å¤§çš„ batch size æ¥åŠ é€Ÿå¯¼å‡º
    data_loader = DataLoader(dataset, batch_size=512, shuffle=False, num_workers=4)

    all_latents, all_labels = [], []
    for img, lbl in data_loader:
        img = img.to(device)
        all_latents.append(encoder(img).cpu().numpy())
        all_labels.append(lbl.numpy())

    all_latents = np.concatenate(all_latents, axis=0)
    all_labels = np.concatenate(all_labels, axis=0)

    # ä½¿ç”¨ Pandas ä¿å­˜ä¸ºå¸¦è¡¨å¤´çš„ CSV
    df_latents = pd.DataFrame(all_latents, columns=[f'dim_{i}' for i in range(LATENT)])
    df_latents['label'] = all_labels

    output_path = CKPT_DIR / f"cifar10_{split_name}_latents.csv"
    df_latents.to_csv(output_path, index=False, float_format="%.6f")
    print(f"âœ… CSV for {split_name} exported to {output_path}")
    print(f"   Latents shape: {all_latents.shape}, Labels shape: {all_labels.shape}")


# ä½¿ç”¨æœ€ä½³æ¨¡å‹å¯¼å‡ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ½œç 
export_latents(CKPT_DIR / 'ae_best.pth', train_ds, 'train')
export_latents(CKPT_DIR / 'ae_best.pth', test_ds, 'test')

writer.close()
total_time = time.time() - start_time
print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æ€»è€—æ—¶: {total_time / 3600:.2f} å°æ—¶")